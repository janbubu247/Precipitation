import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
os.environ["OMP_NUM_THREADS"] = "1"


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, BayesianRidge, LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.mixture import GaussianMixture
from sklearn.metrics import mean_squared_error, r2_score
from openpyxl import load_workbook

excel_path = "China_pivoted_values.xlsx"
header = ["Sample Site Name", "OLS", "Ridge", "Lasso", "BayesianRidge", "KNN", "RandomForest", "Bagging", "Stacking", "GMM"]
output_path = "China_results_by_station.xlsx"

# Load all sheet names
sheet_names = pd.ExcelFile(excel_path).sheet_names
if not os.path.exists(output_path):
    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
        pd.DataFrame(columns=header).to_excel(writer, sheet_name="MSE", index=False)
        pd.DataFrame(columns=header).to_excel(writer, sheet_name="R2", index=False)

models = {
    "OLS": LinearRegression(),
    "Ridge": Ridge(alpha=1.0),
    "Lasso": Lasso(alpha=0.1),
    "BayesianRidge": BayesianRidge(),
    "KNN": KNeighborsRegressor(n_neighbors=5),
    "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Bagging": BaggingRegressor(DecisionTreeRegressor(), n_estimators=100, random_state=42),
    "Stacking": StackingRegressor(
        estimators=[('dt', DecisionTreeRegressor()), ('knn', KNeighborsRegressor())],
        final_estimator=Ridge(), passthrough=True, n_jobs=-1
    )
}

# Function for GMM regression prediction
def gmr_predict(gmm, X_input):
    means = gmm.means_
    covariances = gmm.covariances_
    weights = gmm.weights_

    n_features = X_input.shape[1]
    y_preds = []

    for x in X_input:
        conditional_means = []
        conditional_weights = []

        for k in range(gmm.n_components):
            mu = means[k]
            cov = covariances[k]

            mu_x = mu[:n_features]
            mu_y = mu[n_features:]
            sigma_xx = cov[:n_features, :n_features]
            sigma_yx = cov[n_features:, :n_features]
            sigma_yy = cov[n_features:, n_features:]

            try:
                inv_sigma_xx = np.linalg.inv(sigma_xx)
            except np.linalg.LinAlgError:
                inv_sigma_xx = np.linalg.pinv(sigma_xx)

            mu_cond = mu_y + sigma_yx @ inv_sigma_xx @ (x - mu_x)
            conditional_means.append(mu_cond[0])
            joint = np.concatenate([x, [0]])
            prob = gmm.predict_proba([joint])[0][k]
            conditional_weights.append(prob * weights[k])

        conditional_weights = np.array(conditional_weights)
        conditional_means = np.array(conditional_means)
        if np.sum(conditional_weights) > 0:
            y_pred = np.sum(conditional_weights * conditional_means) / np.sum(conditional_weights)
        else:
            y_pred = np.mean(conditional_means)

        y_preds.append(y_pred)

    return np.array(y_preds)

# Loop over all sheets
for sheet_name in sheet_names:
    try:
        precipitation = pd.read_excel(excel_path, sheet_name=sheet_name, index_col="Sample Date")
        
        if not all(col in precipitation.columns for col in ["H2", "O18", "Precipitation"]):
            print(f"Skipping sheet {sheet_name}: Missing required columns.")
            continue

        df = precipitation[["H2", "O18", "Precipitation"]].copy()
        df.index = pd.to_datetime(df.index, utc=True)
        df = df.dropna(subset=["H2", "O18", "Precipitation"])  # Drop only rows with missing values

        if df.empty:
            print(f"Skipping sheet {sheet_name}: No valid rows after dropping NaNs.")
            continue

        X = df[["H2", "O18"]]
        y = df["Precipitation"]

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

        mse_results = {}
        r2_results = {}

        # Train and evaluate all models
        for name, model in models.items():
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            mse_results[name] = mean_squared_error(y_test, y_pred)
            r2_results[name] = r2_score(y_test, y_pred)

        # GMM
        XY_train = np.hstack([X_train, y_train.values.reshape(-1, 1)])
        gmm = GaussianMixture(n_components=1, covariance_type='full', random_state=42)
        gmm.fit(XY_train)
        y_pred_gmm = gmr_predict(gmm, X_test)
        mse_results["GMM"] = mean_squared_error(y_test, y_pred_gmm)
        r2_results["GMM"] = r2_score(y_test, y_pred_gmm)

        location_name = precipitation["Sample Site Name"].iloc[0] if "Sample Site Name" in precipitation.columns else sheet_name
        mse_df = pd.DataFrame({ "Sample Site Name": [location_name], **{k: [v] for k, v in mse_results.items()} })
        r2_df = pd.DataFrame({ "Sample Site Name": [location_name], **{k: [v] for k, v in r2_results.items()} })

        try:
            with pd.ExcelWriter(output_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
                for sheet, df_result in [("MSE", mse_df), ("R2", r2_df)]:
                    if sheet in writer.book.sheetnames:
                        start_row = writer.book[sheet].max_row
                        df_result.to_excel(writer, sheet_name=sheet, index=False, header=False, startrow=start_row)
                    else:
                        df_result.to_excel(writer, sheet_name=sheet, index=False)
        except FileNotFoundError:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                mse_df.to_excel(writer, sheet_name="MSE", index=False)
                r2_df.to_excel(writer, sheet_name="R2", index=False)

        print(f"Processed: {sheet_name}")

    except Exception as e:
        print(f"Error processing sheet {sheet_name}: {e}")



# import pandas as pd

# # Load the Excel file
# excel_path = "Phillipine_pivoted_values.xlsx"
# xls = pd.ExcelFile(excel_path)

# # Prepare the result list
# results = []

# # Required columns
# required_cols = ["H2", "O18", "Precipitation"]

# # Loop through each sheet
# for sheet in xls.sheet_names:
#     try:
#         precipitation = pd.read_excel(xls, sheet_name=sheet, index_col="Sample Date")
        
#         # Check if required columns are present
#         if not all(col in precipitation.columns for col in required_cols):
#             print(f"Skipping sheet '{sheet}' — missing required columns.")
#             continue
        
#         # Process data
        
#         df = precipitation[required_cols].copy()
#         df.index = pd.to_datetime(df.index, utc=True)

#         # Get location name or fallback to sheet name
#         location = precipitation.get("Sample Site Name", pd.Series([sheet])).iloc[0]

#         # Seasonal filtering
#         df_jjas = df[df.index.month.isin([6, 7, 8])]
#         df_son  = df[df.index.month.isin([9, 10, 11])]
#         df_djf  = df[df.index.month.isin([12, 1, 2])]
#         df_mam  = df[df.index.month.isin([3, 4, 5])]

#         # Collect counts
#         results.append({
#             "Location": location,
#             "JJAS_ALL": len(df_jjas), "JJAS_exist": df_jjas.dropna().shape[0],
#             "SON_ALL": len(df_son),   "SON_exist": df_son.dropna().shape[0],
#             "DJF_ALL": len(df_djf),   "DJF_exist": df_djf.dropna().shape[0],
#             "MAM_ALL": len(df_mam),   "MAM_exist": df_mam.dropna().shape[0],
#         })
    
#     except Exception as e:
#         print(f"Error processing sheet '{sheet}': {e}")

# # Save the summary to Excel
# summary_df = pd.DataFrame(results)
# summary_df.to_excel("Phillipine_seasonal_summary.xlsx", index=False)
# print("Summary saved to seasonal_summary.xlsx")



fig, axs = plt.subplots(2, 2, figsize=(12, 10))

# Define seasons and titles
seasonal_data = [
    (df_jjas, "JJAS (Jun–Sep)", 'blue'),
    (df_son,  "SON (Sep–Nov)", 'green'),
    (df_djf,  "DJF (Dec–Feb)", 'orange'),
    (df_mam,  "MAM (Mar–May)", 'purple')
]

# Plot each season in its subplot
for ax, (df_season, title, color) in zip(axs.flat, seasonal_data):
    ax.scatter(df_season['O18'], df_season['H2'], color=color, s=30)
    ax.set_xlabel('δ¹⁸O (‰)')
    ax.set_ylabel('δ²H (‰)')
    ax.set_title(title)
    ax.grid(True)

plt.tight_layout()
plt.show()


sns.pairplot(df[["H2", "O18", "Precipitation"]])


correlation = df_jjas['O18'].corr(df_jjas['H2'])
print("Correlation between δ¹⁸O and δ²H:", correlation)


print(df[["Precipitation", "H2", "O18"]].corr())



from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X = df[["H2", "O18"]]
X_scaled = scaler.fit_transform(X)


y = df[["Precipitation"]]
Y_scaled = scaler.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)







import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score
from openpyxl import load_workbook

# Store results
mse_results = {}
r2_results = {}

# Evaluate all models (already trained)
for name, model in models.items():
    y_pred = model.predict(X_test)
    mse_results[name] = mean_squared_error(y_test, y_pred)
    r2_results[name] = r2_score(y_test, y_pred)

# GMM
mse_results["GMM"] = mean_squared_error(y_test, y_pred_gmm)
r2_results["GMM"] = r2_score(y_test, y_pred_gmm)

# Assume you are looping over multiple locations (like 'korea-busan', 'mongolia')
location_name = precipitation["Sample Site Name"].iloc[0]  # or "korea-busan", dynamically set in your loop

# Create DataFrames
mse_df = pd.DataFrame({ "Sample Site Name": [location_name], **{k: [v] for k, v in mse_results.items()} })
r2_df = pd.DataFrame({ "Sample Site Name": [location_name], **{k: [v] for k, v in r2_results.items()} })

# Load existing Excel file and write to it
excel_path = "regression_results_by_station.xlsx"

try:
    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
        start_row_mse = writer.sheets["MSE"].max_row
        start_row_r2 = writer.sheets["R2"].max_row

        mse_df.to_excel(writer, sheet_name="MSE", index=False, header=False, startrow=start_row_mse)
        r2_df.to_excel(writer, sheet_name="R2", index=False, header=False, startrow=start_row_r2)

except FileNotFoundError:
    # If file doesn't exist, create new one
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        mse_df.to_excel(writer, sheet_name="MSE", index=False)
        r2_df.to_excel(writer, sheet_name="R2", index=False)



df = pd.read_excel(excel_path)
print(df.head())


# Ordinary Least Squares Regression
# Precipitation=β0 + β1*H2 + β2*O18 + β3*TempAir+⋯+ε

import statsmodels.api as sm

X = sm.add_constant(X)

model = sm.OLS(y, X).fit()
print(model.summary())


precipitation = pd.read_excel("D:/downloads/Japan_pivoted_values.xlsx", index_col="Sample Date", sheet_name="TOKYO")
df2 = precipitation[["H2","O18", "Precipitation"]].copy()



#Ridge Regression - prevent overfitting

from sklearn.linear_model import Ridge

ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)

y_pred = ridge.predict(X_test)

print("Ridge Regression Coefficients:", ridge.coef_)
print("Intercept:", ridge.intercept_)
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R² Score:", r2_score(y_test, y_pred))



from sklearn.linear_model import Lasso

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Lasso regression model
lasso = Lasso(alpha=0.1)  # You can tune alpha
lasso.fit(X_train_scaled, y_train)

# Predictions
y_pred = lasso.predict(X_test_scaled)

# Evaluation
print("Coefficients:", lasso.coef_)
print("Intercept:", lasso.intercept_)
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))




from sklearn.linear_model import BayesianRidge

bayesian_ridge = BayesianRidge()
bayesian_ridge.fit(X_train_scaled, y_train)

# Predict
y_pred = bayesian_ridge.predict(X_test_scaled)

# Evaluation
print("Coefficients:", bayesian_ridge.coef_)
print("Intercept:", bayesian_ridge.intercept_)
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))



from sklearn.neighbors import KNeighborsRegressor

# Create and fit the KNN model
knn = KNeighborsRegressor(n_neighbors=5)  # You can change k (e.g., 3, 7, etc.)
knn.fit(X_train, y_train)

# Predict
y_pred = knn.predict(X_test)

# Evaluate
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))



from sklearn.ensemble import RandomForestRegressor

# Create and train the model
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predict
y_pred = rf.predict(X_test)

# Evaluate
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))



from xgboost import XGBRegressor

# Create DMatrix (optional, but useful for XGBoost)
model = XGBRegressor(
    objective="reg:squarederror",
    n_estimators=100,
    seed=42
)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))



from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor

# Initialize Bagging Regressor with Decision Tree as the base estimator
bagging_model = BaggingRegressor(
    estimator=DecisionTreeRegressor(),  # You can change this to any other regressor
    n_estimators=100,       # Number of base models
    random_state=42,
    n_jobs=-1               # Use all processors
)

# Fit the model
bagging_model.fit(X_train, y_train)

# Predict
y_pred = bagging_model.predict(X_test)

# Evaluate
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))



from sklearn.ensemble import StackingRegressor
from sklearn.linear_model import RidgeCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression

# Define base regressors
base_models = [
    ('dt', DecisionTreeRegressor(random_state=42)),
    ('knn', KNeighborsRegressor()),
]

# Final estimator
final_model = RidgeCV()

# Create stacking regressor
stacking_reg = StackingRegressor(
    estimators=base_models,
    final_estimator=final_model,
    passthrough=True,  # Optional: adds original features to the final regressor
    n_jobs=-1
)

# Train the stacking model
stacking_reg.fit(X_train, y_train)

# Predict
y_pred = stacking_reg.predict(X_test)

# Evaluate
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))




from sklearn.mixture import GaussianMixture
import numpy as np

# Stack X and y into one array for GMM (concatenate along features)
XY = np.hstack([X_train, y_train.values.reshape(-1, 1)])

# Fit Gaussian Mixture Model on joint distribution P(X, y)
gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=42)
gmm.fit(XY)

def gmr_predict(gmm, X_input):
    means = gmm.means_
    covariances = gmm.covariances_
    weights = gmm.weights_

    n_features = X_input.shape[1]
    y_dim = 1  # only predicting precipitation

    y_preds = []

    for x in X_input:
        conditional_means = []
        conditional_weights = []

        for k in range(gmm.n_components):
            mean_k = means[k]
            cov_k = covariances[k]

            # Partition mean and covariance
            mu_x = mean_k[:n_features]
            mu_y = mean_k[n_features:]
            sigma_xx = cov_k[:n_features, :n_features]
            sigma_xy = cov_k[:n_features, n_features:]
            sigma_yx = cov_k[n_features:, :n_features]
            sigma_yy = cov_k[n_features:, n_features:]

            # Conditional mean
            try:
                inv_sigma_xx = np.linalg.inv(sigma_xx)
            except np.linalg.LinAlgError:
                inv_sigma_xx = np.linalg.pinv(sigma_xx)

            mu_y_given_x = mu_y + sigma_yx @ inv_sigma_xx @ (x - mu_x)
            conditional_means.append(mu_y_given_x[0])

            # Compute responsibility (posterior probability)
            joint = np.concatenate([x, [0]])
            prob = gmm.predict_proba([joint])[0][k]
            conditional_weights.append(prob * weights[k])

        # Weighted average of conditional means
        conditional_weights = np.array(conditional_weights)
        conditional_means = np.array(conditional_means)
        if np.sum(conditional_weights) > 0:
            y_pred = np.sum(conditional_weights * conditional_means) / np.sum(conditional_weights)
        else:
            y_pred = np.mean(conditional_means)

        y_preds.append(y_pred)

    return np.array(y_preds)

y_pred = gmr_predict(gmm, X_test)

# Evaluate
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred), OMP_NUM_THREADS=1)    



